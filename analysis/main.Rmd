---
title: "FS20C4 - Steinschlag"
author: "Fernando Millan Villalobos"
date: "February 2020"
output:
  html_document:
    code_folding: show
    echo: TRUE
    warning: FALSE
    message: FALSE
    theme: paper
    df_print: kable
    toc: yes
    toc_depth: 4
    number_sections: yes
    toc_float: 
      collapsed: yes
      smooth_scroll: false
---
## Load additional scripts

```{r config git r version cpus, echo=FALSE}
# CONFIG
# user_name <- "nando" # your Git username (only needed if
# you want to deploy to GH pages)
# project_name <- "rddj-template" # adapt!
package_date <- "2020-03-01" # date of the CRAN snapshot that
# the checkpoint package uses
r_version <- "3.6.3" # R-Version to use
options(Ncpus = 4) # use 4 cores for parallelized installation of packages
if (r_version != paste0(version$major, ".", version$minor)) {
  stop("ERROR: specified R version does not match currently used.")
}
```

# Set up

```{r packages set up wd scientific notation, echo=FALSE}
detach_all_packages <- function() {
  basic_packages_blank <-  c("stats",
                             "graphics",
                             "grDevices",
                             "utils",
                             "datasets",
                             "methods",
                             "base")
  basic_packages <- paste("package:", basic_packages_blank, sep = "")

  package_list <- search()[
    ifelse(unlist(gregexpr("package:", search())) == 1, TRUE, FALSE)]

  package_list <- setdiff(package_list, basic_packages)

  if (length(package_list) > 0)  for (package in package_list) {
    detach(package, character.only = TRUE, unload = TRUE)
    print(paste("package ", package, " detached", sep = ""))
  }
}

detach_all_packages()

# this allows multiple persons to use the same RMarkdown
# without adjusting the working directory by themselves all the time
source("scripts/csf.R")
path_to_wd <- csf() # if this - for some reason - does not work,
# replace with a hardcoded path, like so: "~/projects/rddj-template/analysis/"
if (is.null(path_to_wd) | !dir.exists(path_to_wd)) {
  print("WARNING: No working directory specified for current user")
} else {
  setwd(path_to_wd)
}

# suppress scientific notation
options(scipen = 999)

# unload global rstudioapi and knitr again to avoid conflicts with checkpoint
# this is only necessary if executed within RStudio
# outside of RStudio, namely in the knit.sh script, this causes RMarkdown
# rendering to fail, thus should not be executed there
if (Sys.getenv("RSTUDIO") == "1") {
  detach_all_packages()
}
```

## Define packages

```{r define packages, echo=TRUE, message=FALSE, warning=FALSE}
# from https://mran.revolutionanalytics.com/web/packages/\
# checkpoint/vignettes/using-checkpoint-with-knitr.html
# if you don't need a package, remove it from here (commenting not sufficient)
# tidyverse: see https://blog.rstudio.org/2016/09/15/tidyverse-1-0-0/
cat("
library(rstudioapi)
library(tidyverse) # ggplot2, dplyr, tidyr, readr, purrr, tibble, magrittr
library(scales) # scales for ggplot2
library(jsonlite) # json
library(lintr) # code linting
library(sf) # spatial data handling
library(rmarkdown)
library(cowplot) # theme
library(extrafont)", # fonts
file = "manifest.R")
```

## Install packages

```{r install packages, echo=TRUE, message=FALSE, warning=FALSE}
# if checkpoint is not yet installed, install it (for people using this
# system for the first time)
if (!require(checkpoint)) {
  if (!require(devtools)) {
    install.packages("devtools", repos = "http://cran.us.r-project.org")
    require(devtools)
  }
  devtools::install_github("RevolutionAnalytics/checkpoint",
                           ref = "v0.3.2", # could be adapted later,
                           # as of now (beginning of July 2017
                           # this is the current release on CRAN)
                           repos = "http://cran.us.r-project.org")
  require(checkpoint)
}
# nolint start
if (!dir.exists("~/.checkpoint")) {
  dir.create("~/.checkpoint")
}
# nolint end
# install packages for the specified CRAN snapshot date
checkpoint(snapshotDate = package_date,
           project = path_to_wd,
           verbose = T,
           scanForPackages = T,
           use.knitr = F,
           R.version = r_version)
rm(package_date)
```

## Load packages

```{r load packages sessionInfo, echo=TRUE, message=FALSE, warning=FALSE}
source("manifest.R")
unlink("manifest.R")
sessionInfo()
```

## Load additional scripts

```{r additional scripts, echo=TRUE, message=FALSE, warning=FALSE}
# if you want to outsource logic to other script files, see README for 
# further information
# Load all visualizations functions as separate scripts
knitr::read_chunk("scripts/dviz.supp.R")
source("scripts/dviz.supp.R")
knitr::read_chunk("scripts/themes.R")
source("scripts/themes.R")
knitr::read_chunk("scripts/plot_grid.R")
source("scripts/plot_grid.R")
knitr::read_chunk("scripts/align_legend.R")
source("scripts/align_legend.R")
knitr::read_chunk("scripts/label_log10.R")
source("scripts/label_log10.R")
knitr::read_chunk("scripts/colors.R")
source("scripts/colors.R")
```

# Introduction
This notebook is thought as a working document for the development and documentation of the FS20C4 - Steinschlag project ([FS20C4 - Steinschlag](https://ds-spaces.technik.fhnw.ch/app/uploads/sites/17/2019/09/hs19c4steinschlag-3.pdf)). 

As requested by the village of Schiers (GR), a cursory review of the potential rockfall hazard was performed. This study was conducted to assist the village in determining potential rockfall and setting mitigation actions that can be useful to avoid closure of a section of the roadway that connects Schiers with the outside world. The investigation consisted of a data analysis and a probability calculation carried on by a hired data scientist. The area of study covered the natural bedrock outcrops above the roadway. Protection methods are put into play once rocks have started to destabilize. Typically, rockfall events are mitigated in one of two ways: either passive or active mitigation. In the case of passive mitigations, these cover only the effects of the rockfall and they are generally used in the deposition or run-out zones. Using mesh cable nets to catch falling rocks and contain them as to avoid any damage to the area below represent such a scenario. These methods, also called mitigation efforts, are directed towards avoidance, stabilization, protection and management of risk.

# Data Importing
Originally two different datasets containing rockfalls data (day, hour, mass and speed), one per mountain side, were provided for our analysis ([Dataset 1](https://www.dropbox.com/s/i58gdv6pzi03rhr/out_1.csv?dl=0), [Dataset 2](https://www.dropbox.com/s/3nk9pv7nzz8f0qb/out_2.csv?dl=0)). More data were necessary to know the traffic density within 24 hours in the area. This data come from the report [__Mikrozensus Mobilität und Verkehr 2015__](https://www.bfs.admin.ch/bfs/de/home/statistiken/mobilitaet-verkehr/personenverkehr/verkehrsverhalten.assetdetail.1840604.html) by the Bundesamt für Statistik (BFS). We must point out that the density traffic data per hour available were collected and summarized at national level not at local level. The table with the used data can be found [here](https://www.bfs.admin.ch/bfs/de/home/statistiken/mobilitaet-verkehr/personenverkehr/verkehrsverhalten/tabellen-2015/hauptbericht.assetdetail.2500421.html).  

```{r importing data}
# Import datasets
data01 <- read_csv("input/out_1.csv")
data02 <- read_csv("input/out_2.csv")
data_traffic <- read_csv2("input/tagesverlauf_verkehrsmittel_2015.csv")

# Select columns and rows we are interesting in with values different as na´s
data01 <- data01 %>% 
  select(1:4) %>% 
  na.omit()
data01

data02 <- data02 %>% 
  select(1:4) %>% 
  na.omit()
data02

data_traffic <- data_traffic %>% 
  select(c(1, 8))
data_traffic
```

# Data Pre-Processing
In this step we are going to transform our imported data in a way that allows us to apply further analysis. Typically, this process requires some data wrangling, data transformation and the creation of new variables.

```{r renaming cols parseHour parsing hours}
# Rename columns
names(data01) <- c("date", "time", "mass", "speed")
names(data02) <- c("date", "time", "mass", "speed")
names(data_traffic) <- c("hour", "pct_traffic")

# Parse hour column
hours <- str_split_fixed(data_traffic$hour, " ", n = 2)[, 1] # get the hours interval
hour <- str_split_fixed(hours, "-", n = 2)[, 1] # get the hours starting at 0h.
data_traffic[, 1] <- hour # replace old values with new ones
data_traffic[, 1] <- as.integer(data_traffic$hour) # parse as integer
data_traffic

# Calculating kinetic energy (kJ)
ke <- function(m, s) {
  x <- m
  y <- s
  return(round(.5 * x * y ** 2/1000, 5))
}
data01$energy_kJ <- ke(data01$mass, data01$speed) # adding variable energy to data01
data02$energy_kJ <- ke(data02$mass, data02$speed) # adding variable energy to data02

# Checking the data

# Checking if there´s any NA
sum(is.na(data01)) 
sum(is.na(data02))

# A quick look at the dataframe let us spot a mass value equal to 0 in dataset 02. Let´s check it for both datasets. 
sum(data01$mass == 0)
sum(data02$mass == 0)

# It seems there´s a mass value equal to 0 in dataset 02. As we know that a rock muss have certain weight,
# we get rid off this value and keep the rest of the data.
data02 <-subset(data02, mass != 0)
sum(data02$mass == 0)
```

# Exploratory Data Analysis (EDA)
## Data Summarization
Now we want to describe some important properties of the distribution of the values across the observations in our datasets, an overview of the key properties of the data.

```{r eda summarising}
# Finding the most common value of our different variables in our two samples.
summary(data01)
summary(data02)

# Adding  the variance, the sample standard deviation and the inter-quartile range (IQR).
select(data01, c(mass, speed, energy_kJ)) %>% 
  summarise_each(funs(var, sd, IQR))

select(data02, c(mass, speed, energy_kJ)) %>% 
  summarise_each(funs(var, sd, IQR))
```

## Data Visualization
We´re going to explore and gain insights from our data using one of the most outstanding ability of human beings: capturing visual patterns. Let´s explore distributions of variables in our two datasets: mass, speed and energy.

### Mass Distribution
As we can see in the chart, the most common rockfalls from our dataset 01 are the ones that involves rocks of 500Kg. or less. Events of rock than more than 1500Kg. are rare. Regarding dataset 02, we notice that falling rocks are significant lighter than in the opposite slope. Most common rockfalls are up to 100Kg.

```{r eda visualization plotting mass}

# Chart data01
p1 <- ggplot(data = data01, aes(x = mass)) + 
  geom_histogram(bins = 30, fill = "#22577a") +
  scale_y_continuous(name = "Count", expand = c(0, 0)) +
  scale_x_continuous(name = "Mass (Kg)", breaks = c(seq(0, 3500, 500)), expand = c(0, 0)) + 
  labs(title = "Mass distribution in Dataset 01") +
  coord_cartesian(clip = "off") +
  theme_dviz_hgrid() +
  theme(
    axis.line.x = element_blank(),
    plot.margin = margin(3, 7, 3, 1.5)
  )

# Chart data02
p2 <- ggplot(data = data02, aes(x = mass)) + 
  geom_histogram(bins = 30, fill = "#22577a") +
  scale_y_continuous(name = "Count", expand = c(0, 0)) +
  scale_x_continuous(name = "Mass (Kg)", breaks = c(seq(0, 550, 100)), expand = c(0, 0)) + 
  labs(title = "Mass distribution in Dataset 02") +
  coord_cartesian(clip = "off") +
  theme_dviz_hgrid() +
  theme(
    axis.line.x = element_blank(),
    plot.margin = margin(3, 7, 3, 1.5)
  )

# Plot datasets side by side to ease an overview
plot_grid(
  p1, NULL, p2,
  NULL, NULL, NULL,
  align = 'hv',
  rel_widths = c(1, .04, 1),
  rel_heights = c(1, .04, 1)
)

```

### Speed Distribution
The difference in speed between the two analysed datasets shows us the rocks fall from differente hights. In dataset 01 mean speed is around 9Km./h, while in the other dataset we find that speed is far more spread: with the most ocurrences above 25 Km./h. 

```{r eda visualization plotting speed}

# Chart data01
p1 <- ggplot(data = data01, aes(x = speed)) + 
  geom_histogram(bins = 30, fill = "#22577a") +
  scale_y_continuous(name = "Count", expand = c(0, 0)) +
  scale_x_continuous(name = "Speed (Km/h)", breaks = c(seq(0, 15, 3)), expand = c(0, 0)) + 
  labs(title = "Speed distribution in Dataset 01") +
  coord_cartesian(clip = "off") +
  theme_dviz_hgrid() +
  theme(
    axis.line.x = element_blank(),
    plot.margin = margin(3, 7, 3, 1.5)
  )

# Chart data02
p2 <- ggplot(data = data02, aes(x = speed)) + 
  geom_histogram(bins = 30, fill = "#22577a") +
  scale_y_continuous(name = "Count", expand = c(0, 0)) +
  scale_x_continuous(name = "Speed (Km/h)", breaks = c(seq(0, 55, 5)), expand = c(0, 0)) + 
  labs(title = "Speed distribution in Dataset 02") +
  coord_cartesian(clip = "off") +
  theme_dviz_hgrid() +
  theme(
    axis.line.x = element_blank(),
    plot.margin = margin(3, 7, 3, 1.5)
  )

plot_grid(
  p1, NULL, p2,
  NULL, NULL, NULL,
  align = 'hv',
  rel_widths = c(1, .04, 1),
  rel_heights = c(1, .04, 1)
)

```

### Energy Distribution
Again the differences between our two dataset are quite noticiable. Most rockfalls from heaviest boulders (dataset 01) turn less energy out, max. 50kJ., than the ones from lightest rocks: we find some of them up to 350kJ.

```{r eda visualization plotting energy}

# Chart data01
p1 <- ggplot(data = data01, aes(x = energy_kJ)) + 
  geom_histogram(bins = 30, fill = "#22577a") +
  scale_y_continuous(name = "Count", expand = c(0, 0)) +
  scale_x_continuous(name = "Energy (kJ)", breaks = c(seq(0, 200, 50)), expand = c(0, 0)) + 
  labs(title = "Energy distribution in Dataset 01") +
  coord_cartesian(clip = "off") +
  theme_dviz_hgrid() +
  theme(
    axis.line.x = element_blank(),
    plot.margin = margin(3, 7, 3, 1.5)
  )

# Chart data02
p2 <- ggplot(data = data02, aes(x = energy_kJ)) + 
  geom_histogram(bins = 30, fill = "#22577a") +
  scale_y_continuous(name = "Count", expand = c(0, 0)) +
  scale_x_continuous(name = "Energy (kJ)", breaks = c(seq(0, 450, 50)), expand = c(0, 0)) + 
  labs(title = "Energy distribution in Dataset 02") +
  coord_cartesian(clip = "off") +
  theme_dviz_hgrid() +
  theme(
    axis.line.x = element_blank(),
    plot.margin = margin(3, 7, 3, 1.5)
  )

plot_grid(
  p1, NULL, p2,
  NULL, NULL, NULL,
  align = 'hv',
  rel_widths = c(1, .04, 1),
  rel_heights = c(1, .04, 1)
)

```

### Mass/Speed/Energy relation
Here we show other way what we´ve already noticed above: heavier boulders fall down slower than lighter. Thus, correlation between mass and energy seems to be almost perfect linear. Individual points representation allows us to show how the events (rockfalls) clusters differently around certain x-axis values. In other words, how weight are the falling boulders.

```{r relation between variables}

# Chart mass/speed correlation data01
p1 <- ggplot(data = data01, mapping = aes(x = mass, y = speed)) +
  geom_smooth(mapping = aes(x = mass, y = speed), color = "#22577a", alpha = .2) +
  geom_point(color = "#92929e", size = 1.5) +
  scale_x_continuous(
    limits = c(0, 3200),
    expand = c(0, 0),
    name = "Mass (Kg)") +
  scale_y_continuous(
    limits = c(0, 20),
    expand = c(0, 0),
    name = "Speed (Km/h)"
  ) +
  labs(title = "Mass/Speed correl. Dataset 01") +
  theme_dviz_open()

# Chart mass/speed correlation data02
p2 <- ggplot(data = data02, mapping = aes(x = mass, y = speed)) +
  geom_smooth(mapping = aes(x = mass, y = speed), color = "#22577a", alpha = .2) +
  geom_point(color = "#92929e", size = 1.5) +
  scale_x_continuous(
    limits = c(0, 420),
    expand = c(0, 0),
    name = "Mass (Kg)") +
  scale_y_continuous(
    limits = c(0, 50),
    expand = c(0, 0),
    name = "Speed (Km/h)"
  ) +
  labs(title = "Mass/Speed correl. Dataset 02") +
  theme_dviz_open()

# Chart mass/energy correlation data01
p3 <- ggplot(data = data01, mapping = aes(x = mass, y = energy_kJ)) +
  geom_smooth(mapping = aes(x = mass, y = energy_kJ), color = "#22577a", alpha = .2) +
  geom_point(color = "#92929e", size = 1.5) +
  scale_x_continuous(
    limits = c(0, 3200),
    expand = c(0, 0),
    name = "Mass (Kg)") +
  scale_y_continuous(
    limits = c(0, 200),
    expand = c(0, 0),
    name = "Energy (kJ)"
  ) +
  labs(title = "Mass/Energy correl. Dataset 01") +
  theme_dviz_open()

# Chart mass/energy correlation data02
p4 <- ggplot(data = data02, mapping = aes(x = mass, y = energy_kJ)) +
  geom_smooth(mapping = aes(x = mass, y = energy_kJ), color = "#22577a", alpha = .2) +
  geom_point(color = "#92929e", size = 1.5) +
  scale_x_continuous(
    limits = c(0, 420),
    expand = c(0, 0),
    name = "Mass (Kg)") +
  scale_y_continuous(
    limits = c(0, 400),
    expand = c(0, 0),
    name = "Energy (kJ)"
  ) +
  labs(title = "Mass/Energy correl. Dataset02") +
  theme_dviz_open()

plot_grid(
  p1, NULL, p2,
  NULL, NULL, NULL,
  p3, NULL, p4,
  align = 'hv',
  rel_widths = c(1, .04, 1),
  rel_heights = c(1, .04, 1)
)

```

Let´s bring together all boulders to have an overview.

```{r mass/speed and mass/energy scatterplots}

# Merge both datasets in one
df1_df2 <- rbind(data01, data02)

# Mass/Speed scatterplot
p1 <- ggplot(data = df1_df2, aes(x = speed, y = mass, size = mass)) +
  geom_point(color = "#22577a") +
  scale_x_continuous(name = "Speed (Km/h)") +
  scale_y_continuous(name = "Mass (Kg)") +
  scale_radius(
    name = "Boulder Mass (Kg)",
    guide = guide_legend(
      direction = "horizontal",
      title.position = "top",
      title.hjust = 0.9,
      label.position = "right",
      override.aes = list(fill = "#f0f0f2")
    )
  ) +
  labs(title = "Mass/Speed correlation all boulders") +
  theme_dviz_grid(12) +
  theme(
    legend.position = c(1, 0.9),
    legend.justification = c(1, 0),
    legend.spacing.x = unit(2, "pt"),
    legend.spacing.y = unit(2, "pt"),
    legend.background = element_rect(fill = "white", color = NA),
    legend.key.width = unit(10, "pt"),
    strip.text = element_text(size = 12, margin = margin(2, 0, 2, 0)),
    strip.background  = element_rect(
      fill = "#f0f0f2", colour = "#f0f0f2",
      linetype = 1, size = 0.25
    )
  )

# Mass/Energy scatterplot
p2 <- ggplot(data = df1_df2, aes(x = energy_kJ, y = mass, size = mass)) +
  geom_point(color = "#22577a") +
  scale_x_continuous(name = "Energy (kJ)") +
  scale_y_continuous(name = "Mass (Kg)") +
  scale_radius(
    name = "Boulder Mass (Kg)",
    guide = guide_legend(
      direction = "horizontal",
      title.position = "top",
      title.hjust = 0.9,
      label.position = "right",
      override.aes = list(fill = "#f0f0f2")
    )
  ) +
  labs(title = "Mass/Energy correlation all boulders") +
  theme_dviz_grid(12) +
  theme(
    legend.position = c(1, 0.9),
    legend.justification = c(1, 0),
    legend.spacing.x = unit(2, "pt"),
    legend.spacing.y = unit(2, "pt"),
    legend.background = element_rect(fill = "white", color = NA),
    legend.key.width = unit(10, "pt"),
    strip.text = element_text(size = 12, margin = margin(2, 0, 2, 0)),
    strip.background  = element_rect(
      fill = "#f0f0f2", colour = "#f0f0f2",
      linetype = 1, size = 0.25
    )
  )

plot_grid(
  p1, NULL, p2,
  NULL, NULL, NULL,
  align = 'hv',
  rel_widths = c(1, .04, 1),
  rel_heights = c(1, .04, 1)
)

```

### Rockfalls per Hour
Further, we want to know the distribution of rockfalls per hour from our total number of rockfalls (combined data01 and data02) in our sample period (from 2019-01-01 to 2019-03-27). At what time of day happens the most events?

```{r rockfalls hour}

# Count rockfalls per hour
# rockfalls_hour <- count(df1_df2, time)
# hightlight <- rockfalls_hour %>%
#   mutate(tohighlight = ifelse(n %in% c(9, 8, 7), "yes", "no"))

# Total rockfalls per day
total_rockfalls <- sum(rockfalls_hour$n)

p <- ggplot(data = rockfalls_hour, aes(x = time, y = n)) +
  geom_col(fill = "#22577a", alpha = 0.9) +
  scale_y_continuous(
    name = "Count",
    expand = c(0, 0),
    breaks = c(seq(0, 8, 2))
  ) +
  scale_x_time(
    name = "Time of Day (24 Hours)",
    position = "bottom",
    breaks = unique(rockfalls_hour$time),
    labels = c("0", "1", "2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12", "13", "14", "15", "16", "17", "18", "19", "20", "21", "22", "23")
  ) +
  geom_text(aes(label=rockfalls_hour$n), vjust=1.5, colour="white") +
  labs(title = "Rockfalls per Hour", subtitle = paste("Total Rockfalls from 2019-01-01 to 2019-03-27 (sample period):", total_rockfalls)) +
  coord_cartesian(clip = "off") +
  theme_dviz_hgrid() +
  theme(
    axis.ticks.x = element_blank(),
    axis.line = element_blank(),
    plot.margin = margin(3, 7, 3, 1.5)
  )
p

```

### Traffic Density per Hour
Together with our rockfalls characteristics variables (mass, speed, enery and time), we need to consider data regarding the traffic density in order to carry our next probability calculations out. As the chart show us, no surprisingly the busiest traffic hours are between 16 and 19 pm.

```{r traffic density}

p <- ggplot(data = data_traffic) + 
  geom_step(
    mapping = aes(x = hour, y = pct_traffic),
    color = "#22577a",
    size = 0.75
  ) +
  scale_x_continuous(
    name = "Time of Day (24 Hours)",
    limits = c(0, 24),
    expand = c(0, 0),
    breaks = unique(data_traffic$hour)
  ) +
  scale_y_continuous(
    limits = c(0, 20), 
    expand = c(0, 0), 
    name = "Cumulative Frequency (%)") +
  labs(title = "Traffic Density per Hour") +
  coord_cartesian(clip = "off") +
  theme_dviz_grid() +
  theme(axis.line.x = element_blank())
p

```

# Linting

The code in this RMarkdown is linted with the [lintr package](https://github.com/jimhester/lintr), which is based on the  [tidyverse style guide](http://style.tidyverse.org/). 

```{r linting, echo=TRUE, message=FALSE, warning=FALSE}
lintr::lint("main.Rmd", linters =
              lintr::with_defaults(
                commented_code_linter = NULL,
                trailing_whitespace_linter = NULL
                )
            )
# if you have additional scripts and want them to be linted too, add them here
# lintr::lint("scripts/my_script.R")
```
